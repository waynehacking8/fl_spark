# 基於Spark的聯邦學習

本項目實現了兩種聯邦學習方法：
1. 傳統聯邦學習（Traditional FL）
2. 基於Spark的聯邦學習（Spark FL）

## 項目結構

```
.
├── traditional_code/     # 傳統聯邦學習代碼
├── spark_code/          # 基於Spark的聯邦學習代碼
├── data/               # 數據集
├── evaluation/         # 評估腳本
├── results/           # 結果輸出
└── docker-compose.yml # Docker配置
```

## 環境要求

- Docker
- Docker Compose
- NVIDIA GPU（用於加速訓練）

## 首次啟動

# 移除所有未使用的映像、卷、構建緩存（建議每次訓練前執行）
```bash
cd original
docker compose down
docker system prune -af --volumes
docker builder prune -af
```

# 移除所有未使用image
```bash
docker stop $(docker ps -a -q) && docker rm $(docker ps -a -q) && docker rmi $(docker images -q) -f
```

1. 啟動傳統聯邦學習：
```bash
docker compose run --rm data-init
docker compose up -d fl-server fl-participant-{1..16}
```

2. 啟動基於Spark的聯邦學習：
```bash
docker compose up -d spark-master spark-worker-{1..2}
```
```bash
docker exec -it original-spark-master-1 bash -c "cd /app && python /app/spark_code/main.py"
```
3. 使用現有映像重新啟動：
```bash
docker compose -f docker-compose.yml up -d fl-server fl-participant-1 fl-participant-2 fl-participant-3 fl-participant-4 fl-participant-5 fl-participant-6 fl-participant-7 fl-participant-8 fl-participant-9 fl-participant-10 fl-participant-11 fl-participant-12 fl-participant-13 fl-participant-14 fl-participant-15 fl-participant-16
```

- `docker-compose.yml` 包含所有服務的配置
- 每個參與者分配3,750個訓練樣本
- 使用MNIST數據集進行訓練
- 模型使用CNN架構

## 性能比較

### 架構比較
1. 傳統聯邦學習：
   - 使用Socket通信
   - 16個獨立參與者節點
   - 每個節點處理3,750個樣本
   - 手動管理節點生命週期

2. 基於Spark的聯邦學習：
   - 使用Spark RDD進行數據分發
   - 16個並行分區
   - 每個分區處理3,750個樣本
   - 自動資源分配管理

### 數據吞吐量分析
在相同條件下，兩種方法具有相同的數據處理吞吐量：

1. 數據量：
   - 總樣本數：60,000
   - 每個處理單元：3,750個樣本
   - 並行度：16個處理單元

2. 處理方法：
   - 相同批次大小（32）
   - 相同的本地訓練輪數（5）
   - 相同的模型架構（CNN）
   - 相同的優化器（SGD）

3. 硬件資源：
   - 相同的GPU（NVIDIA GeForce RTX 4070 Ti SUPER）
   - 相同的內存分配（4G限制，2G保留）

4. 聚合策略：
   - 兩種方法均使用聯邦平均
   - 模型聚合在每輪訓練後發生

因此，儘管實現方法不同，兩種方法具有相同的數據處理吞吐量。

### 訓練結果（20 輪，純訓練）

| Round | Trad. Time (s) | Spark Time (s) | Trad. Acc (%) | Spark Acc (%) |
|------:|--------------:|---------------:|--------------:|--------------:|
| 1 | 24.47 | 35.39 | 87.32 | 92.34 |
| 2 | 45.03 | 65.48 | 90.47 | 95.11 |
| 3 | 65.92 | 97.36 | 92.72 | 96.09 |
| 4 | 87.01 | 130.97 | 94.14 | 96.75 |
| 5 | 108.74 | 163.98 | 95.04 | 96.98 |
| 6 | 131.76 | 198.41 | 95.84 | 97.23 |
| 7 | 152.45 | 230.78 | 96.47 | 97.46 |
| 8 | 173.84 | 262.19 | 96.87 | 97.62 |
| 9 | 194.34 | 295.45 | 97.08 | 97.68 |
| 10 | 217.29 | 328.24 | 97.23 | 97.84 |
| 11 | 238.03 | 360.60 | 97.52 | 97.98 |
| 12 | 259.00 | 393.11 | 97.58 | 98.08 |
| 13 | 280.29 | 425.14 | 97.70 | 98.14 |
| 14 | 302.90 | 455.38 | 97.83 | 98.19 |
| 15 | 326.55 | 487.61 | 97.89 | 98.24 |
| 16 | 347.48 | 519.97 | 97.88 | 98.32 |
| 17 | 367.90 | 552.36 | 98.02 | 98.40 |
| 18 | 389.07 | 584.55 | 98.11 | 98.44 |
| 19 | 415.34 | 616.66 | 98.19 | 98.52 |
| 20 | 433.73 | 648.90 | 98.20 | 98.51 |

**總訓練耗時**：
- 傳統 FL：433.73 s
- Spark FL：648.90 s

> Spark FL 理論上應該比傳統 FL 快（利用 Spark 併行與資料局部性），但實測反而慢，主要原因如下：
>
> 1. **GPU 使用差異**：傳統 FL 的 16 個 participant 各自分到 GPU，本地訓練真正跑在 GPU；Spark 範例中只有 `spark-master` 宣告 GPU，兩個 worker 沒有，Executor 其實落在 CPU，導致純計算就慢一倍以上。
> 2. **序列化／反序列化成本**：每輪把 PyTorch `state_dict` 透過 PySpark 傳遞，Spark 先走 JVM ⇄ Python（Py4J）再 pickle，開銷遠高於裸 Socket 傳 blob。
> 3. **RDD→Driver 聚合路徑**：本實作把每個 partition 的更新 collect 回 Driver，再在單執行緒做 FedAvg；傳統 FL 則由 Server 直接接收並行 TCP 流，同步後即可聚合，少了 Spark scheduler 的多層 Callback。
> 4. **容器 I/O 與 Log Overhead**：Spark 會寫 event-log、executor log、shuffle 以及 checkpoint，I/O 峰值造成額外延遲；傳統 FL 只寫少量 CSV/PNG。
> 5. **啟動延遲**：每輪 Spark job 會重新 materialize RDD DAG（沒有長駐 Executor 的優化），participant 則在單一長連線內重複利用模型與資料。
>
> **結論**：要讓 Spark FL 真正加速，需要：
> • 在所有 worker 啟用 GPU（或把計算移到 GPU 支援的 Arrow/UDF）
> • 利用 `mapPartitions` + 全邊分散式聚合（如 parameter server）避免巨量 collect
> • 或者直接用 Horovod-on-Spark 之類支援 NCCL 的方案

如上調整後，Spark 才可能超過傳統 FL 的執行速度。

## 容錯實驗

### 實驗目標
比較傳統FL和Spark FL在面對不同類型故障時的健壯性和恢復能力。

### 故障類型和模擬方法

# 容錯比較實驗計劃

為了評估和比較「傳統聯邦學習」和「基於Spark的聯邦學習」架構在不同故障場景下的健壯性和恢復能力，我們設計了以下核心容錯實驗。所有實驗基於相同的總數據集（60,000個MNIST樣本，均勻分為16個數據分片，每個分片3,750個樣本）和模型架構，以確保公平比較，尤其是在「數據影響平等」原則下。

## 容錯實驗

### 實驗1：訓練期間單個數據分片貢獻失敗

#### 實驗目標
比較當聯邦學習某輪中無法將一個數據分片的處理結果納入全局模型聚合時，反應機制、容錯能力及對整體訓練的影響。

#### 模擬場景
- **傳統聯邦學習：** 在指定訓練輪次（例如第R輪）中，模擬參與者節點（`fl-participant`）意外離線（例如，使用`docker stop`命令停止該參與者容器）。該參與者原本負責一個數據分片的本地訓練，其模型更新在該輪中將無法提交給服務器（`fl-server`）。在此場景中，系統在該輪次中失去**1個數據分片**（3,750個樣本）的處理結果，使用檢查點機制進行故障恢復。

- **基於Spark的聯邦學習：** 在相應輪次R計算開始前，模擬一個數據分片的原始數據文件變得**暫時不可讀**。例如，通過修改該數據文件的系統訪問權限（如`chmod 000 <分片文件路徑>`），使得Spark在該輪執行此分片的本地訓練任務時，因無法讀取源數據而失敗。在此場景中，系統同樣在該輪次中失去**1個數據分片**（3,750個樣本）的處理結果，使用RDD的血統機制進行故障恢復。

#### 觀察重點（通用）
1. **故障檢測：** 系統是否能及時檢測到單個數據分片貢獻的缺失（例如，服務器未收到更新，Spark任務持續失敗）。

2. **當前輪次處理：**
   - 該輪全局模型聚合是否會停滯、失敗或繼續？
   - 如果繼續，聚合機制如何處理缺失的分片貢獻（例如，基於N-1個分片的貢獻進行聚合，或使用其他策略）？

3. **自動化和恢復：** 系統是否有自動化機制處理此類故障？故障解決後（例如，重啟參與者節點，恢復文件權限），後續訓練輪次能否自動恢復正常運行？

4. **性能影響：** 此類故障對單輪訓練時間、整體訓練時間和最終模型準確率的影響程度。

#### 預期比較點
- 比較兩個系統面對單個數據分片貢獻失敗時的策略（例如，傳統FL服務器是否配置了超時放棄或比例聚合邏輯；Spark FL作業是否因單個任務持續失敗而完全失敗，或在應用層是否有容錯聚合邏輯）。

- 評估每種架構下此類故障對訓練連續性和數據完整性的潛在風險。

### 實驗2：中央協調節點故障

#### 實驗目標
比較當每個系統的中央協調控制單元發生故障時，對整體聯邦學習過程、系統可用性和故障恢復複雜性的影響。在此場景中，**所有數據的處理都將受到影響**。

#### 模擬場景
- **傳統聯邦學習：** 在訓練過程中，模擬聯邦服務器（`fl-server`）意外故障（例如，使用`docker stop`命令停止服務器容器），使用檢查點機制進行故障恢復。

- **基於Spark的聯邦學習：** 在訓練過程中，模擬Spark主節點（`spark-master`）意外故障（例如，使用`docker stop`命令停止主節點容器），使用RDD的血統機制進行故障恢復。

#### 觀察重點（通用）
1. **系統即時響應：** 協調節點故障後，分佈式計算單元（`fl-participant` / `spark-worker`及其任務）的行為模式（例如，是否繼續運行，嘗試重新連接，或帶錯誤終止）。

2. **訓練狀態：** 整體訓練過程是否因故障而完全中斷。

3. **恢復流程：**
   - 手動重啟協調節點後，系統能否恢復？
   - 計算單元能否自動重新連接並恢復任務？
   - 訓練能否從故障點繼續，還是需要從頭開始？

4. **狀態丟失風險：** 評估因協調節點故障而丟失訓練進度、全局模型狀態和其他信息的風險。

#### 預期比較點
- 分析兩種架構中中央協調節點的單點故障特性。
- 比較故障恢復的易用性、所需時間和對訓練進度的影響。
- 評估協調節點是否有內置或易於實現的高可用性解決方案。

## 實驗3：多節點故障與恢復

### 實驗目標
評估當多個數據分片同時發生故障並隨後恢復時，兩個系統的容錯能力和恢復效率。

### 模擬場景
1. **故障階段：**
   - **傳統聯邦學習：** 在第5輪訓練期間，同時停止3個參與者節點
     - 具體操作：`docker stop fl-participant-1 fl-participant-2 fl-participant-3`
   - **基於Spark的聯邦學習：** 在第5輪訓練期間，同時使3個數據分片文件不可讀
     - 具體操作：`chmod 000 data/mnist_train_part1.pt data/mnist_train_part2.pt data/mnist_train_part3.pt`

2. **恢復階段：**
   - 在第8輪訓練開始前，恢復所有失敗的節點/文件
     - 傳統FL：`docker start fl-participant-1 fl-participant-2 fl-participant-3`
     - Spark FL：`chmod 644 data/mnist_train_part1.pt data/mnist_train_part2.pt data/mnist_train_part3.pt`

### 觀察重點
1. **故障期間的性能：**
   - 系統是否能夠在失去3個分片（18.75%的數據）的情況下繼續訓練
   - 第5-7輪期間的準確率變化和訓練穩定性

2. **恢復能力：**
   - 系統是否能自動檢測節點/文件恢復並將其重新納入訓練
   - 恢復過程是否需要手動干預
   - 恢復後性能是否恢復正常水平（從第8輪開始）

3. **整體影響：**
   - 臨時故障對最終模型的影響
   - 兩個系統從故障中恢復的速度和完整性

### 預期比較點
- 比較兩個系統在多個節點同時故障場景下的彈性
- 評估自動恢復機制的性能差異和設計複雜性
- 分析臨時部分數據丟失對模型收斂過程的影響

## 實驗4：縮減規模測試

### 實驗目標
評估在資源受限條件下數據分片數量減半時兩個系統的容錯性能。

### 模擬場景
- **標準設置：** 16個數據分片（每個分片3,750個樣本），其中1個發生故障並隨後恢復
- **縮減規模：** 8個數據分片（每個分片7,500個樣本），其中1個發生故障並隨後恢復

在兩種規模下分別測試：
1. **故障階段：**
   - 在第5輪訓練期間，導致1個數據分片/節點失敗
   
2. **恢復階段：**
   - 在第7輪訓練前，恢復失敗的分片/節點

### 觀察重點
1. 縮減規模後單點故障的影響是否增加（因為每個分片包含更多數據）
2. 系統的恢復能力和彈性是否受到規模影響
3. 訓練效率和資源利用率的變化
4. 不同規模下兩種架構的優缺點比較

### 預期比較點
- 分析不同規模下單點故障對整體訓練的影響差異
- 評估哪種架構在小規模部署中具有更好的故障適應性
- 比較規模變化對系統恢復能力的影響

## 實驗5：延遲恢復測試

### 實驗目標
評估不同恢復時間對系統性能的影響，識別最佳恢復時機。

### 模擬場景
在標準設置下（16個數據分片）：
1. **快速恢復組：** 
   - 故障發生在第5輪（1個節點/分片），在第6輪開始前恢復
   
2. **延遲恢復組：** 
   - 故障發生在第5輪（1個節點/分片），在第10輪開始前恢復

### 觀察重點
1. 不同恢復時間對最終模型準確率的影響
2. 恢復延遲是否導致不可逆的性能損失
3. 每個系統對恢復時間的敏感性
4. 訓練過程中的穩定性變化

### 預期比較點
- 分析恢復時間對最終模型性能的影響
- 評估哪種架構對恢復延遲的敏感性較低
- 確定最佳故障恢復時間窗口

## 統一實驗要求

### 數據影響平等原則
- 確保在每個實驗中Traditional FL和Spark FL失敗的數據量完全相同
- 實驗3：同時損失3個分片（11,250個樣本），隨後恢復
- 實驗4：在不同規模下損失1個分片，隨後恢復
- 實驗5：臨時損失1個分片，但恢復時間不同

### 標準化測量
- 為每個實驗記錄相同的指標：訓練時間、準確率曲線、收斂輪數
- 每個實驗重複3次取平均值，以減少隨機因素

### 一致的實驗環境
- 使用相同的硬件配置和網絡環境
- 控制變量法，只改變被測試的參數

### 實驗流程

1. **基準測試**
   - 在無故障情況下運行兩個系統
   - 記錄每輪訓練的測試準確率
   - 建立基準性能曲線

2. **故障測試**
   - 按優先順序進行兩種類型的故障測試
   - 重複每種故障類型多次
   - 記錄所有相關指標

3. **數據收集**
   - 系統日誌
   - 訓練準確率曲線
   - 故障恢復時間
   - 資源利用率

4. **分析和比較**
   - 故障恢復能力
   - 訓練穩定性
   - 最終模型性能
   - 資源利用效率

### 預期結果

1. **節點丟失測試：**
   - Spark FL應自動檢測故障並重試任務
   - 傳統FL可能需要手動干預
   - 兩種方法的模型準確率差異不大

2. **數據分片丟失測試：**
   - 兩種方法都能繼續訓練
   - 準確率可能略有下降
   - 收斂速度可能減慢

### 評估指標

1. **容錯能力**
   - 故障檢測時間
   - 恢復成功率
   - 訓練完成率

2. **性能影響**
   - 每輪訓練時間的變化
   - 最終模型準確率
   - 收斂速度的變化

## 監控

- 傳統FL：通過Docker日誌查看訓練進度
- Spark FL：通過Spark UI監控任務執行

## 實驗設計

### 核心設置

1. 數據集
   - 使用標準MNIST數據集
   - 初始採用IID數據分區
   - 未來擴展到Non-IID場景

2. 模型架構
   - 使用相同的PyTorch CNN模型
   - 確保兩種方法使用相同的架構
   - 固定模型參數和超參數

3. 系統實現
   - Spark FL：
     * 主/從架構
     * 使用Spark廣播分發模型
     * 使用reduce/treeAggregate聚合更新
   - 傳統FL：
     * 客戶端-服務器模式
     * TCP Socket通信
     * 點對點模型更新傳輸

4. 實驗參數
   - 固定總聯邦學習輪數
   - 固定本地訓練Epoch數
   - 使用標準FedAvg聚合策略

### 評估指標

1. 訓練效率
   - 端到端訓練時間
   - 故障恢復時間
   - 資源利用率（CPU/內存）

2. 通信開銷
   - 總數據傳輸量
   - 網絡帶寬利用率
   - 通信延遲

3. 模型性能
   - 每輪測試準確率
   - 最終模型準確率
   - 收斂速度

4. 容錯能力
   - 故障檢測時間
   - 恢復成功率
   - 訓練完成率

### 實驗環境

1. 容器化部署
   - Docker Compose管理
   - 環境一致性保證
   - 自動依賴安裝

2. 監控工具
   - Docker stats
   - Spark UI
   - 自定義日誌

3. 數據收集
   - 實時日誌記錄
   - 性能指標收集
   - 結果文件導出

### 日程安排

1. 第1週：核心實現
   - Spark FL基本流程
   - 數據分發機制
   - 容錯邏輯實現

2. 第2週：系統優化
   - 數據加載優化
   - 評估功能實現
   - 容錯測試

3. 第3週：實驗執行
   - 基準性能測試
   - 故障模擬實驗
   - 數據收集

4. 第4週：分析和報告
   - 數據分析
   - 圖表創建
   - 報告撰寫

### 成功指標

1. 效率提升
   - Spark FL總訓練時間明顯優於傳統FL
   - 考慮容錯開銷後仍保持優勢

2. 通信優化
   - 顯著減少總通信開銷
   - 改進網絡利用率

3. 可比較的性能
   - 無故障時的相似準確率
   - 故障後的可接受水平

4. 容錯驗證
   - 成功完成計劃的訓練輪數
   - 故障恢復時間在可接受範圍內

### 未來擴展

1. 功能擴展
   - 與Spark MLlib深度整合
   - 動態參與者選擇
   - 差分隱私保護

2. 架構優化
   - 實時聯邦學習
   - 自適應參數調整
   - 監控系統集成

## 執行提示和性能觀察


### 權限/I/O設置
1. **結果目錄寫入權限**
   如果由Docker映射的`results/`目錄由root創建，則可能無法從容器內部寫入。請在主機上執行：
   ```bash
   sudo chown -R 1001:1001 results data
   ```
   其中`1001`是bitnami基礎映像的默認非root用戶。

2. **預分割MNIST分片**
   - `data-init`服務已修改為運行`traditional_code/prepare_mnist.py`，該程序僅在首次啟動時下載並生成
     `mnist_train_part1.pt … mnist_train_part16.pt`（每個3,750個樣本）。
   - 後續重新運行傳統FL將不再解壓gzip，消除SSD I/O峰值。


