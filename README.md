# 基於Spark的聯邦學習

本項目實現了兩種聯邦學習方法：
1. 傳統聯邦學習（Traditional FL）
2. 基於Spark的聯邦學習（Spark FL）

## 項目結構

```
.
├── traditional_code/     # 傳統聯邦學習代碼
├── spark_code/          # 基於Spark的聯邦學習代碼
├── data/               # 數據集
├── evaluation/         # 評估腳本
├── results/           # 結果輸出
└── docker-compose.yml # Docker配置
```

## 環境要求

- Docker
- Docker Compose
- NVIDIA GPU（用於加速訓練）

## 首次啟動

# 移除所有未使用的映像、卷、構建緩存（建議每次訓練前執行）
```bash
cd original
docker compose down
docker system prune -af --volumes
docker builder prune -af
```

# 移除所有未使用image
```bash
docker stop $(docker ps -a -q) && docker rm $(docker ps -a -q) && docker rmi $(docker images -q) -f
```

1. 啟動傳統聯邦學習：
```bash
docker compose run --rm data-init
docker compose up -d fl-server fl-participant-{1..2}
```

2. 啟動基於Spark的聯邦學習：
```bash
docker compose up -d spark-master spark-worker-1
```
```bash
docker exec -it original-spark-master-1 bash -c "cd /app && python /app/spark_code/main.py"
```
3. 使用現有映像重新啟動：
```bash
docker compose -f docker-compose.yml up -d fl-server fl-participant-1 fl-participant-2 
```

- `docker-compose.yml` 包含所有服務的配置
- 每個參與者分配30000個訓練樣本
- 使用MNIST數據集進行訓練
- 模型使用CNN架構

## 性能比較

### 架構比較
1. 傳統聯邦學習：
   - 使用Socket通信
   - 2個獨立參與者節點
   - 每個節點處理30,000個樣本
   - 手動管理節點生命週期

2. 基於Spark的聯邦學習：
   - 使用Spark RDD進行數據分發
   - 2個並行分區
   - 每個分區處理30,000個樣本
   - 自動資源分配管理

### 數據吞吐量分析
在相同條件下，兩種方法具有相同的數據處理吞吐量：

1. 數據量：
   - 總樣本數：60,000
   - 每個處理單元：30,000個樣本
   - 並行度：2個處理單元

2. 處理方法：
   - 相同批次大小（32）
   - 相同的本地訓練輪數（5）
   - 相同的模型架構（CNN）
   - 相同的優化器（SGD）

3. 硬件資源：
   - 相同的GPU（NVIDIA GeForce RTX 4070 Ti SUPER）
   - 相同的內存分配（4G限制，2G保留）

4. 聚合策略：
   - 兩種方法均使用聯邦平均
   - 模型聚合在每輪訓練後發生

### 訓練結果（20 輪，純訓練）

| Round | Trad. Time (s) | Spark Time (s) | Trad. Acc (%) | Spark Acc (%) |
|------:|--------------:|---------------:|--------------:|--------------:|
| 1 | 36.73 | 12.17 | 97.20 | 96.40 |
| 2 | 69.72 | 22.12 | 97.81 | 97.77 |
| 3 | 99.87 | 32.01 | 98.14 | 98.05 |
| 4 | 132.28 | 41.79 | 98.34 | 98.41 |
| 5 | 165.71 | 52.16 | 98.64 | 98.66 |
| 6 | 199.23 | 62.32 | 98.69 | 98.85 |
| 7 | 233.36 | 71.99 | 98.69 | 98.75 |
| 8 | 266.64 | 81.62 | 98.76 | 98.83 |
| 9 | 300.39 | 91.80 | 98.87 | 98.85 |
| 10 | 334.56 | 101.87 | 98.83 | 98.76 |
| 11 | 366.93 | 111.61 | 98.89 | 98.70 |
| 12 | 401.80 | 121.71 | 98.92 | 98.91 |
| 13 | 432.56 | 131.46 | 98.87 | 98.89 |
| 14 | 466.52 | 141.07 | 98.81 | 98.95 |
| 15 | 499.85 | 150.95 | 98.88 | 98.78 |
| 16 | 532.26 | 160.83 | 98.88 | 98.93 |
| 17 | 566.77 | 170.49 | 98.88 | 98.84 |
| 18 | 597.85 | 180.34 | 98.95 | 98.94 |
| 19 | 631.41 | 190.37 | 98.96 | 98.83 |
| 20 | 664.82 | 199.95 | 98.88 | 98.89 |

**總訓練耗時**：
- 傳統 FL：664.82 s
- Spark FL：199.95 s

> Spark FL 比傳統 FL 快約 3.3 倍，主要原因如下：
>
> 1. **數據分片優化**：將數據分片從 16 個減少到 2 個，每個分片處理 30,000 個樣本，減少了數據傳輸和聚合開銷。
> 2. **GPU 利用率提升**：Spark worker 現在可以充分利用 GPU 資源，避免了 CPU 計算的瓶頸。
> 3. **通信效率**：減少了節點間的通信次數，從 16 個節點減少到 2 個節點，大幅降低了通信開銷。
> 4. **資源分配**：Spark 的自動資源分配機制更有效地利用了系統資源，避免了資源競爭。
> 5. **模型架構統一**：確保了兩種方法使用相同的 CNN 架構（CNNMnist），消除了模型差異帶來的影響。
>
> **結論**：通過優化數據分片策略和資源分配，Spark FL 在保持模型準確率的同時，顯著提升了訓練效率。兩種方法的最終準確率都在 98.8% 左右，但 Spark FL 的訓練時間僅為傳統 FL 的三分之一。

## 容錯實驗

### 實驗目標
比較傳統FL和Spark FL在面對不同類型故障時的健壯性和恢復能力。

### 故障類型和模擬方法

# 容錯比較實驗計劃

為了評估和比較「傳統聯邦學習」和「基於Spark的聯邦學習」架構在不同故障場景下的健壯性和恢復能力，我們設計了以下核心容錯實驗。所有實驗基於相同的總數據集（60,000個MNIST樣本，均勻分為2個數據分片，每個分片30,000個樣本）和模型架構，以確保公平比較，尤其是在「數據影響平等」原則下。

## 容錯實驗

### 實驗1：訓練期間單個數據分片貢獻失敗

#### 實驗目標
比較當聯邦學習某輪中無法將一個數據分片的處理結果納入全局模型聚合時，反應機制、容錯能力及對整體訓練的影響。

#### 模擬場景
- **傳統聯邦學習：** 在指定訓練輪次（例如第R輪）中，模擬參與者節點（`fl-participant`）意外離線（例如，使用`docker stop`命令停止該參與者容器）。該參與者原本負責一個數據分片的本地訓練，其模型更新在該輪中將無法提交給服務器（`fl-server`）。在此場景中，系統在該輪次中失去**1個數據分片**（30,000個樣本）的處理結果，使用檢查點機制進行故障恢復。

- **基於Spark的聯邦學習：** 在相應輪次R計算開始前，模擬一個數據分片的原始數據文件變得**暫時不可讀**。例如，通過修改該數據文件的系統訪問權限（如`chmod 000 <分片文件路徑>`），使得Spark在該輪執行此分片的本地訓練任務時，因無法讀取源數據而失敗。在此場景中，系統同樣在該輪次中失去**1個數據分片**（30,000個樣本）的處理結果，使用RDD的血統機制進行故障恢復。

#### 觀察重點（通用）
1. **故障檢測：** 系統是否能及時檢測到單個數據分片貢獻的缺失（例如，服務器未收到更新，Spark任務持續失敗）。

2. **當前輪次處理：**
   - 該輪全局模型聚合是否會停滯、失敗或繼續？
   - 如果繼續，聚合機制如何處理缺失的分片貢獻（例如，基於N-1個分片的貢獻進行聚合，或使用其他策略）？

3. **自動化和恢復：** 系統是否有自動化機制處理此類故障？故障解決後（例如，重啟參與者節點，恢復文件權限），後續訓練輪次能否自動恢復正常運行？

4. **性能影響：** 此類故障對單輪訓練時間、整體訓練時間和最終模型準確率的影響程度。

#### 預期比較點
- 比較兩個系統面對單個數據分片貢獻失敗時的策略（例如，傳統FL服務器是否配置了超時放棄或比例聚合邏輯；Spark FL作業是否因單個任務持續失敗而完全失敗，或在應用層是否有容錯聚合邏輯）。

- 評估每種架構下此類故障對訓練連續性和數據完整性的潛在風險。

### 實驗2：中央協調節點故障

#### 實驗目標
比較當每個系統的中央協調控制單元發生故障時，對整體聯邦學習過程、系統可用性和故障恢復複雜性的影響。在此場景中，**所有數據的處理都將受到影響**。

#### 模擬場景
- **傳統聯邦學習：** 在訓練過程中，模擬聯邦服務器（`fl-server`）意外故障（例如，使用`docker stop`命令停止服務器容器），使用檢查點機制進行故障恢復。

- **基於Spark的聯邦學習：** 在訓練過程中，模擬Spark主節點（`spark-master`）意外故障（例如，使用`docker stop`命令停止主節點容器），使用RDD的血統機制進行故障恢復。

#### 觀察重點（通用）
1. **系統即時響應：** 協調節點故障後，分佈式計算單元（`fl-participant` / `spark-worker`及其任務）的行為模式（例如，是否繼續運行，嘗試重新連接，或帶錯誤終止）。

2. **訓練狀態：** 整體訓練過程是否因故障而完全中斷。

3. **恢復流程：**
   - 手動重啟協調節點後，系統能否恢復？
   - 計算單元能否自動重新連接並恢復任務？
   - 訓練能否從故障點繼續，還是需要從頭開始？

4. **狀態丟失風險：** 評估因協調節點故障而丟失訓練進度、全局模型狀態和其他信息的風險。

#### 預期比較點
- 分析兩種架構中中央協調節點的單點故障特性。
- 比較故障恢復的易用性、所需時間和對訓練進度的影響。
- 評估協調節點是否有內置或易於實現的高可用性解決方案。

## 實驗3：GPU資源故障

### 實驗目標
評估當GPU資源發生故障時，兩個系統的容錯能力和恢復效率。

### 模擬場景
1. **故障階段：**
   - **傳統聯邦學習：** 在第5輪訓練期間，模擬一個參與者節點的GPU故障
     - 具體操作：`nvidia-smi -r` 或修改 CUDA_VISIBLE_DEVICES
   - **基於Spark的聯邦學習：** 在第5輪訓練期間，模擬一個worker的GPU故障
     - 具體操作：`nvidia-smi -r` 或修改 CUDA_VISIBLE_DEVICES

2. **恢復階段：**
   - 在第8輪訓練開始前，恢復GPU資源
     - 具體操作：重啟GPU服務或恢復CUDA_VISIBLE_DEVICES設置

### 觀察重點
1. **故障期間的性能：**
   - 系統是否能夠在失去一個GPU的情況下繼續訓練
   - 第5-7輪期間的準確率變化和訓練穩定性
   - CPU回退訓練的性能影響

2. **恢復能力：**
   - 系統是否能自動檢測GPU恢復並重新啟用
   - 恢復過程是否需要手動干預
   - 恢復後性能是否恢復正常水平

3. **整體影響：**
   - 臨時GPU故障對最終模型的影響
   - 兩個系統從故障中恢復的速度和完整性
   - 資源切換的開銷

### 預期比較點
- 比較兩個系統在GPU故障場景下的彈性
- 評估自動恢復機制的性能差異
- 分析臨時資源降級對模型收斂過程的影響

## 實驗4：混合故障測試

### 實驗目標
評估在同時發生多種類型故障時，兩個系統的綜合容錯能力。

### 模擬場景
在標準設置下（2個數據分片）：
1. **故障組合：** 
   - 在第5輪訓練期間，同時發生：
     * 一個參與者節點故障
     * GPU資源故障
     * 網絡延遲增加
   
2. **恢復階段：**
   - 在第8輪訓練前，逐步恢復所有故障

### 觀察重點
1. 多故障疊加對系統穩定性的影響
2. 故障恢復的優先順序和策略
3. 系統在複雜故障場景下的自適應能力
4. 最終模型性能的影響程度

### 預期比較點
- 分析多故障場景下的系統行為差異
- 評估故障恢復策略的有效性
- 比較兩個系統的整體穩定性

## 統一實驗要求

### 數據影響平等原則
- 確保在每個實驗中Traditional FL和Spark FL失敗的數據量完全相同
- 實驗1：損失1個分片（30,000個樣本）
- 實驗3：GPU故障影響1個分片（30,000個樣本）
- 實驗4：混合故障影響1個分片（30,000個樣本）

### 標準化測量
- 為每個實驗記錄相同的指標：訓練時間、準確率曲線、收斂輪數
- 每個實驗重複3次取平均值，以減少隨機因素

### 一致的實驗環境
- 使用相同的硬件配置和網絡環境
- 控制變量法，只改變被測試的參數

### 實驗流程

1. **基準測試**
   - 在無故障情況下運行兩個系統
   - 記錄每輪訓練的測試準確率
   - 建立基準性能曲線

2. **故障測試**
   - 按優先順序進行各類故障測試
   - 重複每種故障類型多次
   - 記錄所有相關指標

3. **數據收集**
   - 系統日誌
   - 訓練準確率曲線
   - 故障恢復時間
   - 資源利用率
   - GPU使用情況

4. **分析和比較**
   - 故障恢復能力
   - 訓練穩定性
   - 最終模型性能
   - 資源利用效率

### 預期結果

1. **節點丟失測試：**
   - Spark FL應自動檢測故障並重試任務
   - 傳統FL可能需要手動干預
   - 兩種方法的模型準確率差異不大

2. **GPU故障測試：**
   - 兩種方法都能繼續訓練
   - 準確率可能略有下降
   - 收斂速度可能減慢
   - 資源切換開銷可接受

3. **混合故障測試：**
   - 系統能夠處理多種故障
   - 恢復後性能接近基準水平
   - 訓練過程保持穩定

## 監控

- 傳統FL：通過Docker日誌查看訓練進度
- Spark FL：通過Spark UI監控任務執行

## 實驗設計

### 核心設置

1. 數據集
   - 使用標準MNIST數據集
   - 初始採用IID數據分區
   - 總樣本數：60,000
   - 每個節點分配：30,000個樣本
   - 分區數量：2個

2. 模型架構
   - 使用CNNMnist模型（統一命名）
   - 確保兩種方法使用相同的架構
   - 固定模型參數和超參數：
     * 批次大小：32
     * 本地訓練輪數：5
     * 優化器：SGD
     * 學習率：0.01

3. 系統實現
   - Spark FL：
     * 主/從架構（1個master，2個worker）
     * 使用Spark RDD進行數據分發
     * 使用reduce/treeAggregate聚合更新
     * GPU加速支持
   - 傳統FL：
     * 客戶端-服務器模式（1個server，2個client）
     * TCP Socket通信
     * 點對點模型更新傳輸
     * GPU加速支持

4. 實驗參數
   - 固定總聯邦學習輪數：20
   - 固定本地訓練Epoch數：5
   - 使用標準FedAvg聚合策略
   - 每輪訓練後進行模型評估

### 評估指標

1. 訓練效率
   - 端到端訓練時間
   - 每輪訓練時間
   - 資源利用率（GPU/內存）

2. 通信開銷
   - 總數據傳輸量
   - 網絡帶寬利用率
   - 通信延遲

3. 模型性能
   - 每輪測試準確率
   - 最終模型準確率
   - 收斂速度

4. 容錯能力
   - 故障檢測時間
   - 恢復成功率
   - 訓練完成率

### 實驗環境

1. 容器化部署
   - Docker Compose管理
   - 環境一致性保證
   - 自動依賴安裝
   - GPU支持配置

2. 監控工具
   - Docker stats
   - Spark UI
   - 自定義日誌
   - GPU使用監控

3. 數據收集
   - 實時日誌記錄
   - 性能指標收集
   - 結果文件導出
   - 準確率曲線繪製

### 容錯實驗設計

1. 單節點故障測試
   - 模擬一個參與者節點故障
   - 觀察系統恢復能力
   - 記錄訓練中斷時間
   - 評估模型性能影響

2. 通信故障測試
   - 模擬網絡延遲
   - 模擬數據包丟失
   - 測試超時處理
   - 評估系統穩定性

3. 資源競爭測試
   - 模擬GPU資源競爭
   - 測試內存使用峰值
   - 評估系統彈性
   - 記錄性能降級

### 成功指標

1. 效率提升
   - Spark FL總訓練時間優於傳統FL
   - 考慮容錯開銷後仍保持優勢
   - GPU利用率達到預期水平

2. 通信優化
   - 顯著減少總通信開銷
   - 改進網絡利用率
   - 降低通信延遲

3. 可比較的性能
   - 無故障時的相似準確率
   - 故障後的可接受水平
   - 穩定的收斂過程

4. 容錯驗證
   - 成功完成計劃的訓練輪數
   - 故障恢復時間在可接受範圍內
   - 系統自動恢復能力

### 未來擴展

1. 功能擴展
   - 與Spark MLlib深度整合
   - 動態參與者選擇
   - 差分隱私保護
   - 異構設備支持

2. 架構優化
   - 實時聯邦學習
   - 自適應參數調整
   - 監控系統集成
   - 分布式存儲優化

## 執行提示和性能觀察


### 權限/I/O設置
1. **結果目錄寫入權限**
   如果由Docker映射的`results/`目錄由root創建，則可能無法從容器內部寫入。請在主機上執行：
   ```bash
   sudo chown -R 1001:1001 results data
   ```
   其中`1001`是bitnami基礎映像的默認非root用戶。

2. **預分割MNIST分片**
   - `data-init`服務已修改為運行`traditional_code/prepare_mnist.py`，該程序僅在首次啟動時下載並生成
     `mnist_train_part1.pt … mnist_train_part16.pt`（每個3,750個樣本）。
   - 後續重新運行傳統FL將不再解壓gzip，消除SSD I/O峰值。


