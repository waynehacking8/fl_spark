#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Traditional FL Participant for CIFAR-10 with Fault Simulation
å‚³çµ±è¯é‚¦å­¸ç¿’CIFAR-10åƒèˆ‡è€…å¯¦ç¾ï¼Œæ”¯æŒæ•…éšœæ¨¡æ“¬
"""

import socket
import pickle
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import time
import logging
import sys
import struct
import os

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥æ¨¡å‹
sys.path.append('..')
from models import get_model

# è¨­ç½®æ—¥èªŒï¼ˆå…ˆç”¨é»˜èªIDï¼Œå¾Œé¢æœƒæ›´æ–°ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format=f'%(asctime)s - CIFAR10-Participant - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

HEADER_SIZE = 8

def recv_all(sock, n):
    """æ¥æ”¶æŒ‡å®šå­—ç¯€æ•¸çš„æ•¸æ“š"""
    data = bytearray()
    while len(data) < n:
        try:
            packet = sock.recv(n - len(data))
            if not packet:
                return None
            data.extend(packet)
        except Exception as e:
            logging.error(f"recv_all error: {e}")
            return None
    return data

def recv_msg(sock, header_size=HEADER_SIZE):
    """æ¥æ”¶å®Œæ•´æ¶ˆæ¯"""
    try:
        raw_msglen = recv_all(sock, header_size)
        if not raw_msglen:
            return None
        msglen = struct.unpack('>Q', raw_msglen)[0]
        raw_msg = recv_all(sock, msglen)
        if raw_msg is None:
            return None
        return pickle.loads(raw_msg)
    except Exception as e:
        logging.error(f"recv_msg error: {e}")
        return None

def send_msg(sock, data, header_size=HEADER_SIZE):
    """ç™¼é€å®Œæ•´æ¶ˆæ¯"""
    try:
        msg = pickle.dumps(data)
        msg = struct.pack('>Q', len(msg)) + msg
        sock.sendall(msg)
        return True
    except Exception as e:
        logging.error(f"send_msg error: {e}")
        return False

class CIFAR10FLParticipant:
    def __init__(self, participant_id, server_host='localhost', server_port=9999, 
                 data_dir='../data', model_type='standard', batch_size=32, learning_rate=0.001, local_epochs=5,
                 experiment_mode='normal', num_total_participants=2):
        self.participant_id = participant_id
        self.server_host = server_host
        self.server_port = server_port
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.local_epochs = local_epochs
        self.experiment_mode = experiment_mode
        
        # é˜²æ­¢éæ“¬åˆçš„åƒæ•¸
        self.weight_decay = 1e-4  # L2æ­£å‰‡åŒ–
        self.dropout_rate = 0.3   # å¢åŠ dropout
        
        # è¨­å‚™é…ç½®
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logging.info(f"åƒèˆ‡è€… {self.participant_id} ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = get_model(model_type=model_type).to(self.device)
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)
        
        # å­¸ç¿’ç‡èª¿åº¦å™¨ - æ¯5è¼ªæ¸›å°‘å­¸ç¿’ç‡
        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.8)
        
        # å¯¦é©—æ¨¡å¼é…ç½®
        self._configure_experiment_mode()
        
        # åŠ è¼‰æœ¬åœ°æ•¸æ“š
        self._load_local_data()
        
        logging.info(f"CIFAR-10 åƒèˆ‡è€… {self.participant_id} åˆå§‹åŒ–å®Œæˆ")
        logging.info(f"å¯¦é©—æ¨¡å¼: {self.experiment_mode}")

    def _configure_experiment_mode(self):
        """é…ç½®å¯¦é©—æ¨¡å¼åƒæ•¸"""
        if self.experiment_mode == 'normal':
            # æ­£å¸¸æ¨¡å¼ï¼šç„¡æ•…éšœæ³¨å…¥
            self.fault_round = None
            self.failed_participants = []
            logging.info("ğŸ”„ æ­£å¸¸æ¨¡å¼ï¼šç„¡æ•…éšœæ³¨å…¥")
            
        elif self.experiment_mode == 'exp1':
            # å¯¦é©—1ï¼šæ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—ï¼ˆç¬¬5è¼ªåƒèˆ‡è€…1é›¢ç·šï¼‰
            self.fault_round = 5
            self.failed_participants = [1]
            logging.info("ğŸ§ª å¯¦é©—1æ¨¡å¼ï¼šç¬¬5è¼ªæ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—")
            
        elif self.experiment_mode == 'exp2':
            # å¯¦é©—2ï¼šWorkerç¯€é»æ•…éšœï¼ˆç¬¬8è¼ªåƒèˆ‡è€…1é›¢ç·šï¼‰
            self.fault_round = 8
            self.failed_participants = [1]
            logging.info("ğŸ”§ å¯¦é©—2æ¨¡å¼ï¼šç¬¬8è¼ªWorkerç¯€é»æ•…éšœ")
            
        else:
            raise ValueError(f"Unknown experiment mode: {self.experiment_mode}")

    def _load_local_data(self):
        """åŠ è¼‰æœ¬åœ°CIFAR-10æ•¸æ“šåˆ†ç‰‡"""
        data_file = f'../data/cifar10_train_part{self.participant_id}.pt'
        
        if not os.path.exists(data_file):
            logging.error(f"æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
            raise FileNotFoundError(f"æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        
        logging.info(f"æ­£åœ¨åŠ è¼‰æ•¸æ“šæ–‡ä»¶: {data_file}")
        
        # åŠ è¼‰æ•¸æ“š
        data = torch.load(data_file, map_location='cpu')
        images = data['data']
        labels = data['targets']
        
        # å‰µå»ºæ•¸æ“šé›†å’Œæ•¸æ“šåŠ è¼‰å™¨
        dataset = TensorDataset(images, labels)
        self.data_loader = DataLoader(
            dataset, 
            batch_size=self.batch_size, 
            shuffle=True,
            num_workers=0,  # é¿å…å¤šé€²ç¨‹å•é¡Œ
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        self.data_size = len(dataset)
        
        logging.info(f"æ•¸æ“šåŠ è¼‰å®Œæˆ:")
        logging.info(f"  æ¨£æœ¬æ•¸: {self.data_size}")
        logging.info(f"  æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        logging.info(f"  æ‰¹æ¬¡æ•¸: {len(self.data_loader)}")
        logging.info(f"  æ•¸æ“šå½¢ç‹€: {images.shape}")

    def should_participate(self, round_num):
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²åƒèˆ‡æœ¬è¼ªè¨“ç·´ï¼ˆæ•…éšœæ¨¡æ“¬ï¼‰"""
        if (self.fault_round is not None and round_num == self.fault_round and 
            self.participant_id in self.failed_participants):
            
            if self.experiment_mode == 'exp1':
                logging.warning(f"ğŸ§ª åƒèˆ‡è€… {self.participant_id} åœ¨ç¬¬ {round_num} è¼ªæ¨¡æ“¬æ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—")
            elif self.experiment_mode == 'exp2':
                logging.warning(f"ğŸ”§ åƒèˆ‡è€… {self.participant_id} åœ¨ç¬¬ {round_num} è¼ªæ¨¡æ“¬Workerç¯€é»æ•…éšœ")
            
            return False
        return True

    def local_train(self, global_model_state):
        """æœ¬åœ°è¨“ç·´"""
        logging.info(f"é–‹å§‹ç¬¬ {self.current_round} è¼ªæœ¬åœ°è¨“ç·´...")
        
        # åŠ è¼‰å…¨å±€æ¨¡å‹
        self.model.load_state_dict(global_model_state)
        self.model.train()
        
        total_loss = 0.0
        num_batches = 0
        
        for epoch in range(self.local_epochs):
            epoch_loss = 0.0
            epoch_batches = 0
            
            for batch_idx, (data, targets) in enumerate(self.data_loader):
                data, targets = data.to(self.device), targets.to(self.device)
                
                # å‰å‘å‚³æ’­
                self.optimizer.zero_grad()
                outputs = self.model(data)
                loss = self.criterion(outputs, targets)
                
                # åå‘å‚³æ’­
                loss.backward()
                self.optimizer.step()
                
                epoch_loss += loss.item()
                epoch_batches += 1
                
                if batch_idx % 50 == 0:
                    logging.debug(f"Epoch {epoch+1}/{self.local_epochs}, "
                                f"Batch {batch_idx}/{len(self.data_loader)}, "
                                f"Loss: {loss.item():.4f}")
            
            avg_epoch_loss = epoch_loss / epoch_batches
            total_loss += avg_epoch_loss
            num_batches += epoch_batches
            
            logging.info(f"Epoch {epoch+1}/{self.local_epochs} å®Œæˆ, "
                        f"å¹³å‡æå¤±: {avg_epoch_loss:.4f}")
        
        avg_total_loss = total_loss / self.local_epochs
        logging.info(f"æœ¬åœ°è¨“ç·´å®Œæˆï¼Œå¹³å‡æå¤±: {avg_total_loss:.4f}")
        
        # æ›´æ–°å­¸ç¿’ç‡èª¿åº¦å™¨
        self.scheduler.step()
        current_lr = self.optimizer.param_groups[0]['lr']
        logging.info(f"ç•¶å‰å­¸ç¿’ç‡: {current_lr:.6f}")
        
        return self.model.state_dict()

    def connect_to_server(self):
        """é€£æ¥åˆ°æœå‹™å™¨"""
        for attempt in range(3):
            try:
                client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                client_socket.settimeout(30.0)
                client_socket.connect((self.server_host, self.server_port))
                logging.info(f"æˆåŠŸé€£æ¥åˆ°æœå‹™å™¨ (å˜—è©¦ {attempt+1}/3)")
                return client_socket
            except Exception as e:
                logging.warning(f"é€£æ¥å¤±æ•— (å˜—è©¦ {attempt+1}/3): {e}")
                if attempt < 2:
                    time.sleep(5)
        
        logging.error("ç„¡æ³•é€£æ¥åˆ°æœå‹™å™¨")
        return None

    def run_federated_round(self, round_num):
        """åŸ·è¡Œå–®è¼ªè¯é‚¦å­¸ç¿’"""
        self.current_round = round_num
        logging.info(f"=== åƒèˆ‡è€… {self.participant_id} - ç¬¬ {round_num} è¼ª ===")
        
        # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åƒèˆ‡
        if not self.should_participate(round_num):
            logging.warning(f"åƒèˆ‡è€… {self.participant_id} è·³éç¬¬ {round_num} è¼ªï¼ˆæ•…éšœæ¨¡æ“¬ï¼‰")
            return False
        
        # é€£æ¥æœå‹™å™¨
        client_socket = self.connect_to_server()
        if client_socket is None:
            return False
        
        try:
            # ç™¼é€åƒèˆ‡è€…ä¿¡æ¯
            participant_info = {'participant_id': self.participant_id}
            if not send_msg(client_socket, participant_info):
                logging.error("ç™¼é€åƒèˆ‡è€…ä¿¡æ¯å¤±æ•—")
                return False
            
            # æ¥æ”¶å…¨å±€æ¨¡å‹
            logging.info("æ­£åœ¨æ¥æ”¶å…¨å±€æ¨¡å‹...")
            global_model_state = recv_msg(client_socket)
            if global_model_state is None:
                logging.error("æ¥æ”¶å…¨å±€æ¨¡å‹å¤±æ•—")
                return False
            
            logging.info("å…¨å±€æ¨¡å‹æ¥æ”¶æˆåŠŸ")
            
            # æœ¬åœ°è¨“ç·´
            updated_model_state = self.local_train(global_model_state)
            
            # ç™¼é€æ¨¡å‹æ›´æ–°
            logging.info("æ­£åœ¨ç™¼é€æ¨¡å‹æ›´æ–°...")
            update_data = {
                'model_state': {k: v.cpu() for k, v in updated_model_state.items()},
                'data_size': self.data_size,
                'participant_id': self.participant_id
            }
            
            if not send_msg(client_socket, update_data):
                logging.error("ç™¼é€æ¨¡å‹æ›´æ–°å¤±æ•—")
                return False
            
            logging.info(f"ç¬¬ {round_num} è¼ªå®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"ç¬¬ {round_num} è¼ªå‡ºéŒ¯: {e}")
            return False
        finally:
            client_socket.close()

    def run(self, num_rounds=20):
        """é‹è¡Œè¯é‚¦å­¸ç¿’"""
        logging.info(f"ğŸš€ åƒèˆ‡è€… {self.participant_id} é–‹å§‹ CIFAR-10 è¯é‚¦å­¸ç¿’")
        
        # åƒèˆ‡è€…å•Ÿå‹•å»¶é²ï¼ˆé¿å…åŒæ™‚é€£æ¥ï¼‰
        startup_delay = self.participant_id * 2
        logging.info(f"å•Ÿå‹•å»¶é² {startup_delay} ç§’...")
        time.sleep(startup_delay)
        
        successful_rounds = 0
        
        try:
            for round_num in range(1, num_rounds + 1):
                success = self.run_federated_round(round_num)
                if success:
                    successful_rounds += 1
                
                # è¼ªæ¬¡é–“ä¼‘æ¯
                time.sleep(1)
            
            logging.info(f"ğŸ‰ åƒèˆ‡è€… {self.participant_id} å®Œæˆè¯é‚¦å­¸ç¿’")
            logging.info(f"æˆåŠŸåƒèˆ‡ {successful_rounds}/{num_rounds} è¼ª")
            
        except KeyboardInterrupt:
            logging.info(f"âŒ åƒèˆ‡è€… {self.participant_id} è¢«ä¸­æ–·")
        except Exception as e:
            logging.error(f"âŒ åƒèˆ‡è€… {self.participant_id} å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CIFAR-10 Federated Learning Participant')
    parser.add_argument('--participant_id', type=int, required=True, help='Participant ID (1 or 2)')
    parser.add_argument('--host', type=str, default='localhost', help='Server host')
    parser.add_argument('--port', type=int, default=9999, help='Server port')
    parser.add_argument('--model', type=str, default='resnet', choices=['simple', 'standard', 'resnet'],
                       help='Model type')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--epochs', type=int, default=5, help='Local epochs')
    parser.add_argument('--rounds', type=int, default=20, help='Total rounds')
    parser.add_argument('--mode', type=str, default='normal', choices=['normal', 'exp1', 'exp2'],
                       help='Experiment mode: normal, exp1 (data shard failure), exp2 (worker failure)')
    
    args = parser.parse_args()
    
    # é©—è­‰åƒèˆ‡è€…ID
    if args.participant_id < 1 or args.participant_id > 2:
        print("åƒèˆ‡è€…IDå¿…é ˆæ˜¯1æˆ–2")
        sys.exit(1)
    
    # æ›´æ–°æ—¥èªŒæ ¼å¼
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    logging.basicConfig(
        level=logging.INFO,
        format=f'%(asctime)s - CIFAR10-Participant{args.participant_id} - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )
    
    # å‰µå»ºä¸¦é‹è¡Œåƒèˆ‡è€…
    participant = CIFAR10FLParticipant(
        participant_id=args.participant_id,
        server_host=args.host,
        server_port=args.port,
        model_type=args.model,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        local_epochs=args.epochs,
        experiment_mode=args.mode
    )
    
    participant.run(num_rounds=args.rounds)

if __name__ == "__main__":
    main() 