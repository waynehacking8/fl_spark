#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Traditional FL Server for CIFAR-10 with Fault Tolerance
å‚³çµ±è¯é‚¦å­¸ç¿’CIFAR-10æœå‹™å™¨å¯¦ç¾ï¼Œæ”¯æŒæ•…éšœå®¹éŒ¯
"""

import socket
import pickle
import torch
import torch.nn as nn
import time
import threading
import logging
import os
import sys
import struct
from typing import Dict, List, Tuple
import copy

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥æ¨¡å‹
sys.path.append('..')
from models import get_model

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - CIFAR10-Server - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

HEADER_SIZE = 8

def recv_all(sock, n):
    """æ¥æ”¶æŒ‡å®šå­—ç¯€æ•¸çš„æ•¸æ“š"""
    data = bytearray()
    while len(data) < n:
        try:
            packet = sock.recv(n - len(data))
            if not packet:
                return None
            data.extend(packet)
        except Exception as e:
            logging.error(f"recv_all error: {e}")
            return None
    return data

def recv_msg(sock, header_size=HEADER_SIZE):
    """æ¥æ”¶å®Œæ•´æ¶ˆæ¯"""
    try:
        raw_msglen = recv_all(sock, header_size)
        if not raw_msglen:
            return None
        msglen = struct.unpack('>Q', raw_msglen)[0]
        raw_msg = recv_all(sock, msglen)
        if raw_msg is None:
            return None
        return pickle.loads(raw_msg)
    except Exception as e:
        logging.error(f"recv_msg error: {e}")
        return None

def send_msg(sock, data, header_size=HEADER_SIZE):
    """ç™¼é€å®Œæ•´æ¶ˆæ¯"""
    try:
        msg = pickle.dumps(data)
        msg = struct.pack('>Q', len(msg)) + msg
        sock.sendall(msg)
        return True
    except Exception as e:
        logging.error(f"send_msg error: {e}")
        return False

class CIFAR10FLServer:
    def __init__(self, host='localhost', port=9999, num_participants=2, num_rounds=20, 
                 model_type='standard', fault_detection_timeout=30, experiment_mode='normal'):
        self.host = host
        self.port = port
        self.num_participants = num_participants
        self.num_rounds = num_rounds
        self.fault_detection_timeout = fault_detection_timeout
        self.experiment_mode = experiment_mode  # 'normal', 'exp1', 'exp2'
        
        # è¨­å‚™é…ç½®
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logging.info(f"ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.global_model = get_model(model_type=model_type).to(self.device)
        self.criterion = nn.CrossEntropyLoss()
        
        # çµæœå­˜å„²
        self.results = []
        self.results_dir = f"../results/traditional/{experiment_mode}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # å¯¦é©—æ¨¡å¼é…ç½®
        self._configure_experiment_mode()
        
        # åˆå§‹åŒ–çµæœæ–‡ä»¶
        self.init_results_file()
        
        logging.info(f"CIFAR-10 FL Server åˆå§‹åŒ–å®Œæˆ")
        logging.info(f"å¯¦é©—æ¨¡å¼: {self.experiment_mode}")
        logging.info(f"åƒèˆ‡è€…æ•¸é‡: {self.num_participants}")
        logging.info(f"è¨“ç·´è¼ªæ•¸: {self.num_rounds}")
        logging.info(f"æ•…éšœå®¹éŒ¯è¶…æ™‚: {self.fault_detection_timeout}ç§’")

    def _configure_experiment_mode(self):
        """é…ç½®å¯¦é©—æ¨¡å¼åƒæ•¸"""
        if self.experiment_mode == 'normal':
            # æ­£å¸¸æ¨¡å¼ï¼šç„¡æ•…éšœæ³¨å…¥
            self.fault_round = None
            self.failed_participants = []
            logging.info("ğŸ”„ æ­£å¸¸æ¨¡å¼ï¼šç„¡æ•…éšœæ³¨å…¥")
            
        elif self.experiment_mode == 'exp1':
            # å¯¦é©—1ï¼šæ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—ï¼ˆç¬¬5è¼ªåƒèˆ‡è€…1é›¢ç·šï¼‰
            self.fault_round = 5
            self.failed_participants = [1]
            logging.info("ğŸ§ª å¯¦é©—1æ¨¡å¼ï¼šç¬¬5è¼ªæ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—")
            
        elif self.experiment_mode == 'exp2':
            # å¯¦é©—2ï¼šWorkerç¯€é»æ•…éšœï¼ˆç¬¬8è¼ªåƒèˆ‡è€…1é›¢ç·šï¼‰
            self.fault_round = 8
            self.failed_participants = [1]
            logging.info("ğŸ”§ å¯¦é©—2æ¨¡å¼ï¼šç¬¬8è¼ªWorkerç¯€é»æ•…éšœ")
            
        else:
            raise ValueError(f"Unknown experiment mode: {self.experiment_mode}")

    def init_results_file(self):
        """åˆå§‹åŒ–çµæœæ–‡ä»¶"""
        results_file = os.path.join(self.results_dir, f'cifar10_{self.experiment_mode}_results.csv')
        with open(results_file, 'w') as f:
            f.write("Round,Timestamp,Accuracy,Loss,Participants,Failed_Participants,Mode\n")
        logging.info(f"çµæœæ–‡ä»¶å·²åˆå§‹åŒ–: {results_file}")

    def evaluate_model(self):
        """è©•ä¼°å…¨å±€æ¨¡å‹"""
        self.global_model.eval()
        
        # åŠ è¼‰æ¸¬è©¦æ•¸æ“š
        test_data = torch.load('../data/cifar10_test.pt')
        test_dataset = torch.utils.data.TensorDataset(test_data['data'], test_data['targets'])
        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)
        
        correct = 0
        total = 0
        total_loss = 0.0
        
        with torch.no_grad():
            for data, targets in test_loader:
                data, targets = data.to(self.device), targets.to(self.device)
                outputs = self.global_model(data)
                loss = self.criterion(outputs, targets)
                total_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()
        
        accuracy = 100 * correct / total
        avg_loss = total_loss / len(test_loader)
        
        return accuracy, avg_loss

    def federated_averaging(self, model_updates: List[Dict], weights: List[int]):
        """è¯é‚¦å¹³å‡ç®—æ³•"""
        if not model_updates:
            logging.warning("æ²’æœ‰æ¨¡å‹æ›´æ–°ï¼Œè·³éèšåˆ")
            return
        
        # è¨ˆç®—æ¬Šé‡
        total_samples = sum(weights)
        normalized_weights = [w / total_samples for w in weights]
        
        # èšåˆæ¨¡å‹åƒæ•¸
        global_state_dict = {}
        
        # ç²å–åŸå§‹æ¨¡å‹åƒæ•¸ä½œç‚ºæ¨¡æ¿
        reference_state = self.global_model.state_dict()
        
        # åˆå§‹åŒ– - ä¿æŒæ•¸æ“šé¡å‹
        for key in model_updates[0].keys():
            global_state_dict[key] = torch.zeros_like(reference_state[key]).to(self.device)
        
        # åŠ æ¬Šå¹³å‡ - å…ˆè½‰ç‚ºfloatè¨ˆç®—å†è½‰å›åŸé¡å‹
        for i, update in enumerate(model_updates):
            weight = normalized_weights[i]
            for key in update.keys():
                # ç§»å‹•åˆ°è¨­å‚™ä¸¦è½‰ç‚ºfloaté€²è¡Œè¨ˆç®—
                param_tensor = update[key].to(self.device)
                original_dtype = global_state_dict[key].dtype
                
                # è½‰ç‚ºfloaté€²è¡Œè¨ˆç®—
                if param_tensor.dtype != torch.float32:
                    param_tensor = param_tensor.float()
                if global_state_dict[key].dtype != torch.float32:
                    global_state_dict[key] = global_state_dict[key].float()
                
                # åŸ·è¡ŒåŠ æ¬Šæ±‚å’Œ
                global_state_dict[key] += weight * param_tensor
                
                # è½‰å›åŸå§‹é¡å‹
                if original_dtype != torch.float32:
                    global_state_dict[key] = global_state_dict[key].to(original_dtype)
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(global_state_dict)
        logging.info(f"æ¨¡å‹èšåˆå®Œæˆï¼Œä½¿ç”¨ {len(model_updates)} å€‹æ›´æ–°")

    def handle_participant(self, client_socket, participant_id, round_num):
        """è™•ç†å–®å€‹åƒèˆ‡è€…çš„é€£æ¥"""
        try:
            # ç™¼é€å…¨å±€æ¨¡å‹
            global_state_dict = {k: v.cpu() for k, v in self.global_model.state_dict().items()}
            if not send_msg(client_socket, global_state_dict):
                return None
            
            # æ¥æ”¶æ¨¡å‹æ›´æ–°
            update_data = recv_msg(client_socket)
            if update_data is None:
                return None
            
            model_update = update_data['model_state']
            data_size = update_data['data_size']
            
            logging.info(f"æ”¶åˆ°åƒèˆ‡è€… {participant_id} çš„æ›´æ–°ï¼Œæ•¸æ“šé‡: {data_size}")
            return {'model_state': model_update, 'data_size': data_size, 'participant_id': participant_id}
            
        except Exception as e:
            logging.error(f"è™•ç†åƒèˆ‡è€… {participant_id} æ™‚å‡ºéŒ¯: {e}")
            return None
        finally:
            client_socket.close()

    def run_federated_round(self, round_num, total_start_time):
        """åŸ·è¡Œå–®è¼ªè¯é‚¦å­¸ç¿’"""
        logging.info(f"=== ç¬¬ {round_num} è¼ªé–‹å§‹ ({self.experiment_mode}æ¨¡å¼) ===")
        round_start_time = time.time()
        
        # å‰µå»ºæœå‹™å™¨å¥—æ¥å­—
        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)  # WSLå¯èƒ½ä¸æ”¯æŒ
        
        # å˜—è©¦ç¶å®šç«¯å£ï¼Œå¦‚æœå¤±æ•—å‰‡ç­‰å¾…é‡è©¦
        max_bind_attempts = 3
        for attempt in range(max_bind_attempts):
            try:
                server_socket.bind((self.host, self.port))
                break
            except OSError as e:
                if attempt < max_bind_attempts - 1:
                    logging.warning(f"ç«¯å£ç¶å®šå¤±æ•— (å˜—è©¦ {attempt+1}/{max_bind_attempts}): {e}")
                    time.sleep(2)
                else:
                    raise e
        
        server_socket.listen(self.num_participants)
        server_socket.settimeout(1.0)  # éé˜»å¡accept
        
        # ç­‰å¾…åƒèˆ‡è€…é€£æ¥
        connected_participants = []
        failed_participants = []
        connection_start_time = time.time()
        
        expected_participants = self.num_participants
        
        # æ•…éšœæ³¨å…¥é‚è¼¯
        if (self.fault_round is not None and round_num == self.fault_round and 
            self.failed_participants):
            expected_participants = self.num_participants - len(self.failed_participants)
            if self.experiment_mode == 'exp1':
                logging.warning(f"ğŸ§ª ç¬¬ {round_num} è¼ªæ•¸æ“šåˆ†ç‰‡è²¢ç»å¤±æ•—ï¼šåƒèˆ‡è€… {self.failed_participants} é›¢ç·š")
            elif self.experiment_mode == 'exp2':
                logging.warning(f"ğŸ”§ ç¬¬ {round_num} è¼ªWorkerç¯€é»æ•…éšœï¼šåƒèˆ‡è€… {self.failed_participants} é›¢ç·š")
        
        logging.info(f"ç­‰å¾… {expected_participants} å€‹åƒèˆ‡è€…é€£æ¥...")
        
        while len(connected_participants) < expected_participants:
            try:
                elapsed_time = time.time() - connection_start_time
                if elapsed_time > self.fault_detection_timeout:
                    logging.warning(f"â° æ•…éšœæª¢æ¸¬è¶…æ™‚ ({self.fault_detection_timeout}s)ï¼Œä½¿ç”¨å¯ç”¨åƒèˆ‡è€…ç¹¼çºŒ")
                    break
                
                client_socket, addr = server_socket.accept()
                
                # æ¥æ”¶åƒèˆ‡è€…ID
                participant_info = recv_msg(client_socket)
                if participant_info:
                    participant_id = participant_info['participant_id']
                    logging.info(f"åƒèˆ‡è€… {participant_id} å·²é€£æ¥")
                    connected_participants.append((client_socket, participant_id))
                
            except socket.timeout:
                continue
            except Exception as e:
                logging.error(f"é€£æ¥éŒ¯èª¤: {e}")
        
        server_socket.close()
        
        # ç­‰å¾…socketå®Œå…¨é‡‹æ”¾
        time.sleep(1)
        
        # ä¸¦è¡Œè™•ç†åƒèˆ‡è€…
        model_updates = []
        weights = []
        threads = []
        results = [None] * len(connected_participants)
        
        def worker(i, client_socket, participant_id):
            results[i] = self.handle_participant(client_socket, participant_id, round_num)
        
        # å•Ÿå‹•è™•ç†ç·šç¨‹
        for i, (client_socket, participant_id) in enumerate(connected_participants):
            thread = threading.Thread(target=worker, args=(i, client_socket, participant_id))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰ç·šç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # æ”¶é›†æœ‰æ•ˆçµæœ
        for result in results:
            if result is not None:
                model_updates.append(result['model_state'])
                weights.append(result['data_size'])
        
        # è¨˜éŒ„æ•…éšœåƒèˆ‡è€…
        active_participants = len(model_updates)
        failed_count = self.num_participants - active_participants
        
        if failed_count > 0:
            logging.warning(f"âš ï¸  ç¬¬ {round_num} è¼ªæœ‰ {failed_count} å€‹åƒèˆ‡è€…å¤±æ•—")
        
        # èšåˆæ¨¡å‹
        if model_updates:
            self.federated_averaging(model_updates, weights)
        else:
            logging.error(f"âŒ ç¬¬ {round_num} è¼ªæ²’æœ‰æ”¶åˆ°ä»»ä½•æ¨¡å‹æ›´æ–°")
            return
        
        # è©•ä¼°æ¨¡å‹
        accuracy, loss = self.evaluate_model()
        cumulative_time = time.time() - total_start_time  # ä½¿ç”¨ç´¯è¨ˆæ™‚é–“
        
        # è¨˜éŒ„çµæœ
        self.results.append({
            'round': round_num,
            'timestamp': cumulative_time,  # ç´¯è¨ˆæ™‚é–“
            'accuracy': accuracy,
            'loss': loss,
            'participants': active_participants,
            'failed_participants': failed_count,
            'mode': self.experiment_mode
        })
        
        # ä¿å­˜çµæœåˆ°CSV
        results_file = os.path.join(self.results_dir, f'cifar10_{self.experiment_mode}_results.csv')
        with open(results_file, 'a') as f:
            f.write(f"{round_num},{cumulative_time:.2f},{accuracy:.2f},{loss:.4f},"
                   f"{active_participants},{failed_count},{self.experiment_mode}\n")
        
        # ä¿å­˜æ¨¡å‹æª¢æŸ¥é»
        checkpoint_path = os.path.join(self.results_dir, f'model_round_{round_num}.pth')
        torch.save(self.global_model.state_dict(), checkpoint_path)
        
        logging.info(f"ç¬¬ {round_num} è¼ªå®Œæˆ:")
        logging.info(f"  æº–ç¢ºç‡: {accuracy:.2f}%")
        logging.info(f"  æå¤±: {loss:.4f}")
        logging.info(f"  ç´¯è¨ˆç”¨æ™‚: {cumulative_time:.2f}ç§’")
        logging.info(f"  åƒèˆ‡è€…: {active_participants}/{self.num_participants}")

    def run(self):
        """é‹è¡Œè¯é‚¦å­¸ç¿’"""
        logging.info("ğŸš€ CIFAR-10 è¯é‚¦å­¸ç¿’é–‹å§‹")
        total_start_time = time.time()  # è¨˜éŒ„ç¸½é–‹å§‹æ™‚é–“
        
        try:
            for round_num in range(1, self.num_rounds + 1):
                self.run_federated_round(round_num, total_start_time)
                
                # çŸ­æš«ä¼‘æ¯
                time.sleep(5)  # å¢åŠ å»¶é²ç¢ºä¿socketé‡‹æ”¾
            
            total_time = time.time() - total_start_time
            final_accuracy = self.results[-1]['accuracy'] if self.results else 0
            
            logging.info("ğŸ‰ CIFAR-10 è¯é‚¦å­¸ç¿’å®Œæˆ!")
            logging.info(f"ç¸½ç”¨æ™‚: {total_time:.2f}ç§’")
            logging.info(f"æœ€çµ‚æº–ç¢ºç‡: {final_accuracy:.2f}%")
            
            # ä¿å­˜æœ€çµ‚æ¨¡å‹
            final_model_path = os.path.join(self.results_dir, 'final_model.pth')
            torch.save(self.global_model.state_dict(), final_model_path)
            logging.info(f"æœ€çµ‚æ¨¡å‹å·²ä¿å­˜: {final_model_path}")
            
        except KeyboardInterrupt:
            logging.info("âŒ è¯é‚¦å­¸ç¿’è¢«ä¸­æ–·")
        except Exception as e:
            logging.error(f"âŒ è¯é‚¦å­¸ç¿’å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CIFAR-10 Federated Learning Server')
    parser.add_argument('--port', type=int, default=9999, help='Server port')
    parser.add_argument('--participants', type=int, default=2, help='Number of participants')
    parser.add_argument('--rounds', type=int, default=20, help='Number of federated rounds')
    parser.add_argument('--model', type=str, default='simple', choices=['simple', 'standard', 'resnet'],
                       help='Model type')
    parser.add_argument('--timeout', type=int, default=30, help='Fault detection timeout')
    parser.add_argument('--mode', type=str, default='normal', choices=['normal', 'exp1', 'exp2'],
                       help='Experiment mode: normal, exp1 (data shard failure), exp2 (worker failure)')
    
    args = parser.parse_args()
    
    # å‰µå»ºä¸¦é‹è¡Œæœå‹™å™¨
    server = CIFAR10FLServer(
        port=args.port,
        num_participants=args.participants,
        num_rounds=args.rounds,
        model_type=args.model,
        fault_detection_timeout=args.timeout,
        experiment_mode=args.mode
    )
    
    server.run()

if __name__ == "__main__":
    main() 