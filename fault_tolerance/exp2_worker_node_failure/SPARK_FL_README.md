# EXP2 Spark FL Worker ç¯€é»æ•…éšœå®¹éŒ¯å¯¦é©—

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åƒ…é‹è¡Œ Spark FL å¯¦é©—
```bash
./run_spark_fl.sh
```

### å®Œæ•´å°æ¯”å¯¦é©— (Traditional FL + Spark FL)
```bash
./run_complete_exp2.sh
```

## ğŸ—ï¸ Spark FL æ¶æ§‹

```
Spark Master (Driver)
â”œâ”€â”€ Worker 1 (è™•ç†åˆ†å€ 0, 1)
â””â”€â”€ Worker 2 (è™•ç†åˆ†å€ 2, 3)

æ•…éšœå ´æ™¯ï¼šç¬¬8è¼ªæ™‚åˆ†å€ 0, 1 æ•…éšœ
- æ¨¡æ“¬ participant 1&2 é›¢ç·š
- RDD è¡€çµ±è¿½è¹¤è‡ªå‹•é‡è¨ˆç®—å¤±æ•—åˆ†å€
- ç„¡éœ€äººå·¥å¹²é 
```

## ğŸ“Š å¯¦é©—é‡é»

### æ•…éšœæ³¨å…¥æ©Ÿåˆ¶
- **ç¬¬8è¼ª**ï¼šåˆ†å€ 0 å’Œ 1 æ¨¡æ“¬æ•…éšœ
- **æ•…éšœé¡å‹**ï¼šWorker ç¯€é»å®Œå…¨ç„¡éŸ¿æ‡‰ (60ç§’å»¶é²)
- **é æœŸè¡Œç‚º**ï¼šSpark è‡ªå‹•æª¢æ¸¬ä¸¦é‡æ–°èª¿åº¦å¤±æ•—ä»»å‹™

### RDD å®¹éŒ¯å„ªå‹¢
1. **è¡€çµ±è¿½è¹¤**ï¼šè‡ªå‹•è¨˜éŒ„æ•¸æ“šè®Šæ›éç¨‹
2. **åˆ†å€æ¢å¾©**ï¼šåªé‡è¨ˆç®—å¤±æ•—çš„åˆ†å€
3. **é›¶å¹²é **ï¼šç„¡éœ€æ‰‹å‹•é‡å•Ÿç¯€é»
4. **ç§’ç´šæª¢æ¸¬**ï¼šå¿«é€Ÿè­˜åˆ¥ä»»å‹™å¤±æ•—

## ğŸ“ çµæœæ–‡ä»¶

åŸ·è¡Œå®Œæˆå¾Œæª¢æŸ¥ï¼š
- `results/spark/results.csv` - è¨“ç·´çµæœ
- `results/spark/performance.png` - æ€§èƒ½åœ–è¡¨
- `results/spark/spark_fault_tolerance_analysis.png` - æ•…éšœåˆ†æåœ–
- `results/exp2_fl_comparison.png` - å°æ¯”åœ–è¡¨ (å¦‚æœé‹è¡Œå®Œæ•´å¯¦é©—)

## ğŸ”§ æ‰‹å‹•åŸ·è¡Œæ­¥é©Ÿ

1. **æº–å‚™æ•¸æ“š**
   ```bash
   docker compose run --rm data-init
   ```

2. **å•Ÿå‹• Spark é›†ç¾¤**
   ```bash
   docker compose up -d spark-master spark-worker-1 spark-worker-2
   ```

3. **é‹è¡Œå¯¦é©—**
   ```bash
   docker exec -it exp2-spark-master bash -c "cd /app && python /app/main.py"
   ```

4. **åˆ†æçµæœ**
   ```bash
   python analyze_spark_results.py
   ```

## ğŸ¯ é æœŸçµæœ

- **ç¸½è¼ªæ•¸**ï¼š20 è¼ª
- **æ•…éšœè¼ªæ¬¡**ï¼šç¬¬8è¼ªæœ‰æ˜é¡¯å»¶é²
- **æœ€çµ‚æº–ç¢ºç‡**ï¼š~98-99%
- **å®¹éŒ¯é©—è­‰**ï¼šç¬¬8è¼ªå¾Œç¹¼çºŒæ­£å¸¸è¨“ç·´

## ğŸ†š èˆ‡ Traditional FL å°æ¯”

| ç‰¹æ€§ | Traditional FL | Spark FL |
|------|----------------|----------|
| æ•…éšœæª¢æ¸¬ | 60ç§’è¶…æ™‚ | ç§’ç´šè‡ªå‹•æª¢æ¸¬ |
| æ¢å¾©æ©Ÿåˆ¶ | Checkpoint | RDDè¡€çµ±è¿½è¹¤ |
| äººå·¥å¹²é  | éœ€è¦é‡å•Ÿç¯€é» | å®Œå…¨è‡ªå‹• |
| å®¹éŒ¯ç²’åº¦ | ç¯€é»ç´š | åˆ†å€ç´š |

---

**æŠ€è¡“æ£§**ï¼šApache Spark, PySpark, PyTorch, Docker  
**å®¹éŒ¯æ©Ÿåˆ¶**ï¼šRDDè¡€çµ±è¿½è¹¤ + è‡ªå‹•ä»»å‹™é‡æ–°èª¿åº¦ 